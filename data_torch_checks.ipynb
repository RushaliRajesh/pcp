{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ckwrap\n",
    "from normals_init import find_neighs\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pts = np.load(\"xyz_points.npy\")\n",
    "all_norms = np.load(\"init_normals.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighs shape:  (100000, 249, 3)\n",
      "labels shape:  (100000, 249)\n",
      "labels shape: torch.Size([249])\n",
      "ind_clus shape:  torch.Size([23])\n",
      "coords shape:  torch.Size([23, 3])\n",
      "coords after adding random points:  tensor([[-1.0000e+00,  9.0934e-02,  1.1721e+01],\n",
      "        [-1.0000e+00,  1.0145e-01,  1.1705e+01],\n",
      "        [-1.0000e+00,  1.1260e-01,  1.1715e+01],\n",
      "        [-1.0000e+00,  7.9621e-02,  1.1731e+01],\n",
      "        [-1.0000e+00,  7.5980e-02,  1.1725e+01],\n",
      "        [-1.0000e+00,  8.0252e-02,  1.1704e+01],\n",
      "        [-1.0000e+00,  1.1485e-01,  1.1709e+01],\n",
      "        [-1.0000e+00,  9.9300e-02,  1.1695e+01],\n",
      "        [-1.0000e+00,  1.0221e-01,  1.1688e+01],\n",
      "        [-1.0000e+00,  7.8690e-02,  1.1748e+01],\n",
      "        [-1.0000e+00,  6.4145e-02,  1.1736e+01],\n",
      "        [-1.0000e+00,  8.7351e-02,  1.1753e+01],\n",
      "        [-1.0000e+00,  5.8686e-02,  1.1715e+01],\n",
      "        [-1.0000e+00,  8.8460e-02,  1.1756e+01],\n",
      "        [-1.0000e+00,  6.8877e-02,  1.1747e+01],\n",
      "        [-1.0000e+00,  6.3158e-02,  1.1694e+01],\n",
      "        [-1.0000e+00,  1.3373e-01,  1.1717e+01],\n",
      "        [-1.0000e+00,  6.6512e-02,  1.1748e+01],\n",
      "        [-1.0000e+00,  1.3288e-01,  1.1697e+01],\n",
      "        [-1.0000e+00,  1.2878e-01,  1.1691e+01],\n",
      "        [-1.0000e+00,  4.8731e-02,  1.1720e+01],\n",
      "        [-1.0000e+00,  6.6735e-02,  1.1756e+01],\n",
      "        [-1.0000e+00,  6.8291e-02,  1.1763e+01],\n",
      "        [ 0.0000e+00,  3.1113e-02, -1.5992e-02],\n",
      "        [ 0.0000e+00,  5.8614e-03, -3.0530e-02]], dtype=torch.float64)\n",
      "vec2 :  tensor([[ 0.0000e+00,  3.4530e-03, -2.8790e-03],\n",
      "        [ 0.0000e+00, -7.0590e-03,  1.3649e-02],\n",
      "        [ 0.0000e+00, -1.8214e-02,  2.9650e-03],\n",
      "        [ 0.0000e+00,  1.4766e-02, -1.2218e-02],\n",
      "        [ 0.0000e+00,  1.8407e-02, -6.6940e-03],\n",
      "        [ 0.0000e+00,  1.4135e-02,  1.4582e-02],\n",
      "        [ 0.0000e+00, -2.0459e-02,  8.9670e-03],\n",
      "        [ 0.0000e+00, -4.9130e-03,  2.2965e-02],\n",
      "        [ 0.0000e+00, -7.8210e-03,  3.0214e-02],\n",
      "        [ 0.0000e+00,  1.5697e-02, -2.9807e-02],\n",
      "        [ 0.0000e+00,  3.0242e-02, -1.7399e-02],\n",
      "        [ 0.0000e+00,  7.0360e-03, -3.4546e-02],\n",
      "        [ 0.0000e+00,  3.5701e-02,  3.5630e-03],\n",
      "        [ 0.0000e+00,  5.9270e-03, -3.7614e-02],\n",
      "        [ 0.0000e+00,  2.5510e-02, -2.9005e-02],\n",
      "        [ 0.0000e+00,  3.1229e-02,  2.3888e-02],\n",
      "        [ 0.0000e+00, -3.9342e-02,  1.4830e-03],\n",
      "        [ 0.0000e+00,  2.7875e-02, -2.9796e-02],\n",
      "        [ 0.0000e+00, -3.8490e-02,  2.1280e-02],\n",
      "        [ 0.0000e+00, -3.4389e-02,  2.7712e-02],\n",
      "        [ 0.0000e+00,  4.5656e-02, -2.2080e-03],\n",
      "        [ 0.0000e+00,  2.7652e-02, -3.8164e-02],\n",
      "        [ 0.0000e+00,  2.6096e-02, -4.4569e-02],\n",
      "        [-1.0000e+00,  6.3274e-02,  1.1734e+01],\n",
      "        [-1.0000e+00,  8.8526e-02,  1.1749e+01]], dtype=torch.float64)\n",
      "nearest vec magnitude:  tensor([4.4958e-03, 1.5366e-02, 1.8454e-02, 1.9165e-02, 1.9586e-02, 2.0308e-02,\n",
      "        2.2338e-02, 2.3485e-02, 3.1210e-02, 3.3688e-02, 3.4890e-02, 3.5255e-02,\n",
      "        3.5878e-02, 3.8078e-02, 3.8627e-02, 3.9318e-02, 3.9370e-02, 4.0802e-02,\n",
      "        4.3981e-02, 4.4165e-02, 4.5709e-02, 4.7129e-02, 5.1647e-02, 1.1777e+01,\n",
      "        1.1792e+01], dtype=torch.float64)\n",
      "torch.Size([3])\n",
      "after norm:  torch.Size([24, 3]) torch.Size([3])\n",
      "tensor([[-0.0851,  0.0086,  0.9963],\n",
      "        [-0.0850,  0.0096,  0.9963],\n",
      "        [-0.0849,  0.0068,  0.9964],\n",
      "        [-0.0850,  0.0065,  0.9964],\n",
      "        [-0.0851,  0.0068,  0.9963],\n",
      "        [-0.0851,  0.0098,  0.9963],\n",
      "        [-0.0852,  0.0085,  0.9963],\n",
      "        [-0.0852,  0.0087,  0.9963],\n",
      "        [-0.0848,  0.0067,  0.9964],\n",
      "        [-0.0849,  0.0054,  0.9964],\n",
      "        [-0.0848,  0.0074,  0.9964],\n",
      "        [-0.0851,  0.0050,  0.9964],\n",
      "        [-0.0848,  0.0075,  0.9964],\n",
      "        [-0.0848,  0.0058,  0.9964],\n",
      "        [-0.0852,  0.0054,  0.9963],\n",
      "        [-0.0850,  0.0114,  0.9963],\n",
      "        [-0.0848,  0.0056,  0.9964],\n",
      "        [-0.0852,  0.0113,  0.9963],\n",
      "        [-0.0852,  0.0110,  0.9963],\n",
      "        [-0.0850,  0.0041,  0.9964],\n",
      "        [-0.0848,  0.0057,  0.9964],\n",
      "        [-0.0847,  0.0058,  0.9964],\n",
      "        [ 0.0000,  0.8894, -0.4571],\n",
      "        [ 0.0000,  0.1885, -0.9821]], dtype=torch.float64)\n",
      "crs_pdts after norm shape:  torch.Size([24, 3])\n",
      "shapes for dot:  torch.Size([24, 3]) torch.Size([3])\n",
      "dot_pdts shape:  torch.Size([24])\n",
      "area shape:  torch.Size([24])\n",
      "area shape after multi with sign:  torch.Size([24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155082/104509350.py:57: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975993/work/aten/src/ATen/native/TensorShape.cpp:3277.)\n",
      "  dot_pdts = torch.tensordot(crs_pdts, norms[i].T, dims=1) #check done, works as intented\n"
     ]
    }
   ],
   "source": [
    "'''creating patches via clustering'''\n",
    "\n",
    "def process_one_pcd(pts, norms, main_ind):\n",
    "    dists_ori, indices_ori = find_neighs(pts)\n",
    "    neighs = pts[indices_ori]\n",
    "    print(\"neighs shape: \", neighs.shape)\n",
    "    labels_per_row = np.apply_along_axis(lambda row: ckwrap.ckmeans(row, 5).labels, 1, dists_ori)\n",
    "    print(\"labels shape: \",labels_per_row.shape)\n",
    "\n",
    "    pts = torch.from_numpy(pts)\n",
    "    norms = torch.from_numpy(norms)\n",
    "    indices_ori = torch.from_numpy(indices_ori)\n",
    "    labels_per_row = torch.from_numpy(labels_per_row)\n",
    "\n",
    "    for i,( ind, labels) in enumerate(zip(indices_ori, labels_per_row)):\n",
    "        center = pts[i]\n",
    "        print(\"labels shape:\", labels.shape)\n",
    "        for clus in torch.unique(labels, dim=0):\n",
    "            # ind_clus = ind[np.where(labels == clus)]\n",
    "            ind_clus = ind[torch.where(labels==clus)]\n",
    "            print(\"ind_clus shape: \",ind_clus.shape)\n",
    "            coords = pts[ind_clus]\n",
    "            print(\"coords shape: \", coords.shape)\n",
    "\n",
    "            if(coords.shape[0] < 25):\n",
    "                # 2 random integers\n",
    "                for i in range(25-(coords.shape[0])):\n",
    "                    a, b = torch.randint(1, coords.shape[0], (2,))\n",
    "                    a_n, b_n = torch.divide(a, (a+b)), torch.divide(b, (a+b))\n",
    "                    rnd_pt = torch.add(torch.multiply(a_n, (center-coords[a])), torch.multiply(b_n, (center-coords[b]))).unsqueeze(0)\n",
    "                    coords = torch.cat((coords, rnd_pt), dim=0)\n",
    "            else:\n",
    "                coords = coords[:25]\n",
    "            \n",
    "            print(\"coords after adding random points: \", coords)\n",
    "\n",
    "            vec2 = torch.subtract(center,coords)\n",
    "            print(\"vec2 : \", vec2)\n",
    "            print(\"nearest vec magnitude: \", torch.linalg.norm(vec2, dim=1))\n",
    "            closest_ind = torch.argmin(torch.linalg.norm(vec2, dim=1))\n",
    "            closest = coords[closest_ind]\n",
    "            # vec2 = np.delete(coords, closest_ind, axis=0)\n",
    "            vec2 = torch.cat((coords[:closest_ind], coords[closest_ind+1:]), dim=0)\n",
    "            vec1 = torch.subtract(center, closest)\n",
    "            print(vec1.shape)\n",
    "            vec1 = torch.divide(vec1, torch.linalg.norm(vec1))\n",
    "            vec2 = torch.divide(vec2, torch.linalg.norm(vec2, dim=1, keepdim=True))\n",
    "            print(\"after norm: \", vec2.shape, vec1.shape)\n",
    "            print(vec2)\n",
    "            \n",
    "            crs_pdts = torch.cross(vec1.expand_as(vec2), vec2) #check done, works as intented\n",
    "            area = torch.linalg.norm(crs_pdts, dim=1)\n",
    "            crs_pdts = torch.divide(crs_pdts, torch.linalg.norm(crs_pdts, dim=1, keepdim=True))\n",
    "            print(\"crs_pdts after norm shape: \",crs_pdts.shape)\n",
    "            \n",
    "            print(\"shapes for dot: \", crs_pdts.shape, norms[i].shape)\n",
    "            dot_pdts = torch.tensordot(crs_pdts, norms[i].T, dims=1) #check done, works as intented\n",
    "            sign = torch.divide(dot_pdts, np.abs(dot_pdts))\n",
    "            print(\"dot_pdts shape: \",dot_pdts.shape)\n",
    "            print(\"area shape: \",area.shape)\n",
    "            area = torch.multiply(area, sign)\n",
    "            sort_indices = torch.argsort(area)\n",
    "            print(\"area shape after multi with sign: \",area.shape)\n",
    "            # area, orient, ind_clus = area[sort_indices], orient[sort_indices], ind_clus[sort_indices]\n",
    "            # coords_sorted= pts[ind_clus]\n",
    "            sorted_coords = coords[sort_indices]\n",
    "            \n",
    "            return dot_pdts, area, crs_pdts, coords, sorted_coords, vec1, vec2, sign, closest, center\n",
    "        #     mat.append(sorted_coords)\n",
    "        # mat = np.array(mat)\n",
    "        # np.save(\"patches/pcd_\"+str(main_ind)+\"/pnt_\"+str(i)+\".npy\", mat)\n",
    "            # break\n",
    "        break\n",
    "\n",
    "\n",
    "dot_pdts, area, crs_pdts, coords, sorted_coords, vec1, vec2, sign, closest, center = process_one_pcd(all_pts[0], all_norms[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighs shape:  (100000, 249, 3)\n",
      "labels shape:  (100000, 249)\n",
      "0\n",
      "labels shape: torch.Size([249])\n",
      "ind_clus shape:  torch.Size([23])\n",
      "coords shape:  torch.Size([23, 3])\n",
      "magnitudes:  tensor([4.4958e-03, 1.5366e-02, 1.8454e-02, 1.9165e-02, 1.9586e-02, 2.0308e-02,\n",
      "        2.2338e-02, 2.3485e-02, 3.1210e-02, 3.3688e-02, 3.4890e-02, 3.5255e-02,\n",
      "        3.5878e-02, 3.8078e-02, 3.8627e-02, 3.9318e-02, 3.9370e-02, 4.0802e-02,\n",
      "        4.3981e-02, 4.4165e-02, 4.5709e-02, 4.7129e-02, 5.1647e-02, 1.1777e+01,\n",
      "        1.1774e+01], dtype=torch.float64)\n",
      "tensor([ 0.0000,  0.0035, -0.0029], dtype=torch.float64) tensor([-1.0000,  0.0796, 11.7305], dtype=torch.float64)\n",
      "tensor([ 0.0000,  0.7681, -0.6404], dtype=torch.float64) tensor([-0.0851,  0.0086,  0.9963], dtype=torch.float64)\n",
      "tensor([0.7696, 0.0544, 0.0652], dtype=torch.float64)\n",
      "tensor([0.9940, 0.0703, 0.0843], dtype=torch.float64)\n",
      "norms check:  0 torch.Size([3])\n",
      "tensor(0.9833, dtype=torch.float64)\n",
      "dot_pdts shape:  torch.Size([24])\n",
      "area shape:  torch.Size([24])\n",
      "area shape after multi with sign:  torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "'''creating patches via clustering'''\n",
    "\n",
    "def process_one_pcd(pts, norms, main_ind):\n",
    "    dists_ori, indices_ori = find_neighs(pts)\n",
    "    neighs = pts[indices_ori]\n",
    "    print(\"neighs shape: \", neighs.shape)\n",
    "    labels_per_row = np.apply_along_axis(lambda row: ckwrap.ckmeans(row, 5).labels, 1, dists_ori)\n",
    "    print(\"labels shape: \",labels_per_row.shape)\n",
    "\n",
    "    pts = torch.from_numpy(pts)\n",
    "    norms = torch.from_numpy(norms)\n",
    "    indices_ori = torch.from_numpy(indices_ori)\n",
    "    labels_per_row = torch.from_numpy(labels_per_row)\n",
    "\n",
    "    for i,( ind, labels) in enumerate(zip(indices_ori, labels_per_row)):\n",
    "        print(i)\n",
    "        center = pts[i]\n",
    "        print(\"labels shape:\", labels.shape)\n",
    "        for clus in torch.unique(labels, dim=0):\n",
    "            # ind_clus = ind[np.where(labels == clus)]\n",
    "            ind_clus = ind[torch.where(labels==clus)]\n",
    "            print(\"ind_clus shape: \",ind_clus.shape)\n",
    "            coords = pts[ind_clus]\n",
    "            print(\"coords shape: \", coords.shape)\n",
    "\n",
    "            if(coords.shape[0] < 25):\n",
    "                # 2 random integers\n",
    "                for _ in range(25-(coords.shape[0])):\n",
    "                    a, b = torch.randint(1, coords.shape[0], (2,))\n",
    "                    a_n, b_n = torch.divide(a, (a+b)), torch.divide(b, (a+b))\n",
    "                    rnd_pt = torch.add(torch.multiply(a_n, (center-coords[a])), torch.multiply(b_n, (center-coords[b]))).unsqueeze(0)\n",
    "                    coords = torch.cat((coords, rnd_pt), dim=0)\n",
    "            else:\n",
    "                coords = coords[:25]\n",
    "            \n",
    "            # print(\"coords after adding random points: \", coords)\n",
    "\n",
    "            \n",
    "            vec2 = torch.subtract(center, coords)\n",
    "            print(\"magnitudes: \", torch.linalg.norm(vec2, dim=1))\n",
    "            closest_ind = torch.argmin(torch.linalg.norm(vec2, dim=1))\n",
    "            closest = coords[closest_ind]\n",
    "            vec1 = torch.subtract(center, closest)\n",
    "            vec2 = torch.cat((coords[:closest_ind], coords[closest_ind+1:]), dim=0)\n",
    "            print(vec1, vec2[2,:])\n",
    "            vec1 = torch.divide(vec1, torch.linalg.norm(vec1))\n",
    "            vec2 = torch.divide(vec2, torch.linalg.norm(vec2, dim=1, keepdim=True))\n",
    "            print(vec1, vec2[0,:])\n",
    "            crs_pdts = torch.cross(vec1.expand_as(vec2), vec2)\n",
    "            print(crs_pdts[2,:])\n",
    "            area = torch.linalg.norm(crs_pdts, dim=1)\n",
    "            crs_pdts = torch.divide(crs_pdts, torch.linalg.norm(crs_pdts, dim=1, keepdim=True))\n",
    "            print(crs_pdts[2,:])\n",
    "            print(\"norms check: \", i, norms[i].shape)\n",
    "            dot_pdts = torch.tensordot(crs_pdts, norms[i].T, dims=1)\n",
    "            print(dot_pdts[2])\n",
    "            sign = torch.divide(dot_pdts, np.abs(dot_pdts))\n",
    "            print(\"dot_pdts shape: \",dot_pdts.shape)\n",
    "            print(\"area shape: \",area.shape)\n",
    "            area = torch.multiply(area, sign)\n",
    "            sort_indices = torch.argsort(area)\n",
    "            print(\"area shape after multi with sign: \",area.shape)\n",
    "            # area, orient, ind_clus = area[sort_indices], orient[sort_indices], ind_clus[sort_indices]\n",
    "            # coords_sorted= pts[ind_clus]\n",
    "            sorted_coords = coords[sort_indices]\n",
    "            \n",
    "            return dot_pdts, area, crs_pdts, coords, sorted_coords, vec1, vec2, sign, closest, center\n",
    "        #     mat.append(sorted_coords)\n",
    "        # mat = np.array(mat)\n",
    "        # np.save(\"patches/pcd_\"+str(main_ind)+\"/pnt_\"+str(i)+\".npy\", mat)\n",
    "            # break\n",
    "        break\n",
    "\n",
    "\n",
    "dot_pdts, area, crs_pdts, coords, sorted_coords, vec1, vec2, sign, closest, center = process_one_pcd(all_pts[0], all_norms[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7755, 0.7760, 0.7743, 0.7741, 0.7743, 0.7762, 0.7753, 0.7755, 0.7742,\n",
       "        0.7734, 0.7747, 0.7732, 0.7747, 0.7737, 0.7734, 0.7772, 0.7736, 0.7771,\n",
       "        0.7769, 0.7726, 0.7736, 0.7736, 0.1832, 0.1997], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9833,  0.9833,  0.9833,  0.9833,  0.9832,  0.9833,  0.9833,  0.9833,\n",
       "         0.9833,  0.9833,  0.9833,  0.9832,  0.9833,  0.9833,  0.9832,  0.9833,\n",
       "         0.9833,  0.9833,  0.9833,  0.9832,  0.9833,  0.9833, -0.9956,  0.9956],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_pdts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0035, -0.0029], dtype=torch.float64) tensor([ 0.0000, -0.0182,  0.0030], dtype=torch.float64)\n",
      "tensor([ 0.0000,  0.7681, -0.6404], dtype=torch.float64) tensor([ 0.0000, -0.9870,  0.1607], dtype=torch.float64)\n",
      "tensor([-0.5087, -0.0000, -0.0000], dtype=torch.float64)\n",
      "tensor([-1., -0., -0.], dtype=torch.float64)\n",
      "tensor(-0.9956, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# print(coords.shape)\n",
    "# print(closest, all_pts[0][0])\n",
    "\n",
    "vec1 = torch.subtract(center, closest)\n",
    "vec2 = torch.subtract(center, coords[2])\n",
    "print(vec1, vec2)\n",
    "vec1 = torch.divide(vec1, torch.linalg.norm(vec1))\n",
    "vec2 = torch.divide(vec2, torch.linalg.norm(vec2))\n",
    "print(vec1, vec2)\n",
    "crs = torch.cross(vec1, vec2)\n",
    "print(crs)\n",
    "crs = torch.divide(crs, torch.linalg.norm(crs))\n",
    "print(crs)\n",
    "dot = torch.dot(crs, torch.tensor(all_norms[0][0]))\n",
    "print(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0035, -0.0029], dtype=torch.float64) tensor([ 0.0000, -0.0182,  0.0030], dtype=torch.float64)\n",
      "tensor([ 0.0000,  0.7681, -0.6404], dtype=torch.float64) tensor([ 0.0000,  0.7681, -0.6404], dtype=torch.float64)\n",
      "tensor([-0.5087, -0.0000, -0.0000], dtype=torch.float64)\n",
      "tensor([-1., -0., -0.], dtype=torch.float64)\n",
      "tensor(-0.9956, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "vec1 = torch.subtract(center, closest)\n",
    "vec2 = torch.subtract(center, coords)\n",
    "print(vec1, vec2[2,:])\n",
    "vec1 = torch.divide(vec1, torch.linalg.norm(vec1))\n",
    "vec2 = torch.divide(vec2, torch.linalg.norm(vec2, dim=1, keepdim=True))\n",
    "print(vec1, vec2[0,:])\n",
    "crs = torch.cross(vec1.expand_as(vec2), vec2)\n",
    "print(crs[2,:])\n",
    "crs = torch.divide(crs, torch.linalg.norm(crs, dim=1, keepdim=True))\n",
    "print(crs[2,:])\n",
    "dots = torch.tensordot(crs, torch.tensor(all_norms[0][0]).T, dims=1)\n",
    "print(dots[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9956, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "norms = all_norms[0]\n",
    "dots = torch.tensordot(crs, torch.tensor(norms[0]).T, dims=1)\n",
    "print(dots[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
